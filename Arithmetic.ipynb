{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6911fb3a5248149e359d4934bfbf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer,T5ForConditionalGeneration, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchmetrics\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Question</th>\n",
       "      <th>Equation</th>\n",
       "      <th>Input Numbers</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gino has number0 popsicle sticks . i have numb...</td>\n",
       "      <td>what is the sum of our popsicle sticks ?</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>63 50</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lino picked up number0 shells at the seashore ...</td>\n",
       "      <td>how many shells did he pick up in all ?</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>292 324</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there were number0 parents in the program and ...</td>\n",
       "      <td>how many people were present in the program ?</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>105 698</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>last saturday marie sold number0 magazines and...</td>\n",
       "      <td>what is the total number of reading materials ...</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>425 275</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>there are number0 birds on the fence . number1...</td>\n",
       "      <td>how many birds are on the fence ?</td>\n",
       "      <td>+ number0 number1</td>\n",
       "      <td>12 8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                        Description  \\\n",
       "1  gino has number0 popsicle sticks . i have numb...   \n",
       "2  lino picked up number0 shells at the seashore ...   \n",
       "3  there were number0 parents in the program and ...   \n",
       "4  last saturday marie sold number0 magazines and...   \n",
       "5  there are number0 birds on the fence . number1...   \n",
       "\n",
       "0                                           Question           Equation  \\\n",
       "1           what is the sum of our popsicle sticks ?  + number0 number1   \n",
       "2            how many shells did he pick up in all ?  + number0 number1   \n",
       "3      how many people were present in the program ?  + number0 number1   \n",
       "4  what is the total number of reading materials ...  + number0 number1   \n",
       "5                  how many birds are on the fence ?  + number0 number1   \n",
       "\n",
       "0 Input Numbers Output  \n",
       "1         63 50    113  \n",
       "2       292 324    616  \n",
       "3       105 698    803  \n",
       "4       425 275    700  \n",
       "5          12 8     20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../ArithOpsTrain.xlsx')\n",
    "header = df.iloc[0][1:]\n",
    "df = df.drop('Table 1',axis=1)\n",
    "df = df[1:]\n",
    "df.columns = header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile 90th is of length 239.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_desc = df.Description.apply(lambda x:len(x))\n",
    "length_q = df.Question.apply(lambda x:len(x))\n",
    "length_overall = np.asarray(length_desc) + np.asarray(length_q)\n",
    "perc_90 = np.quantile(length_overall,0.9)\n",
    "print('percentile 90th is of length', perc_90)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(length_desc)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(length_q)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(length_overall)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((930, 5), (49, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X, val_df = train_test_split(df, test_size=0.15, random_state=123)\n",
    "train_df, test_df = train_test_split(df, test_size=0.05, random_state=123)\n",
    "\n",
    "train_df.shape, test_df.shape#, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        tokenizer: T5Tokenizer, \n",
    "        text_max_token_len: int = 512,\n",
    "        eqn_max_token_len: int = 10\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.eqn_max_token_len = eqn_max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        data_row = self.data.iloc[idx]\n",
    "\n",
    "        text = [data_row['Question'], data_row['Description']]\n",
    "        eqn = data_row['Equation']\n",
    "\n",
    "        text_encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt')\n",
    "\n",
    "        eqn_encoding = self.tokenizer(\n",
    "            eqn,\n",
    "            max_length=self.eqn_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        labels = eqn_encoding['input_ids']\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(\n",
    "            text=text,\n",
    "            eqn=eqn,\n",
    "            text_input_ids=text_encoding['input_ids'].flatten(),\n",
    "            text_attention_mask=text_encoding['attention_mask'].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "            labels_attention_mask=eqn_encoding['attention_mask'].flatten()\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        text_max_token_len: int = 512,\n",
    "        eqn_max_token_len: int = 10\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.eqn_max_token_len = eqn_max_token_len\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = ArithmeticDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.eqn_max_token_len\n",
    "        )\n",
    "\n",
    "        self.test_dataset = ArithmeticDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.eqn_max_token_len\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/ankitsingh1/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 't5-base'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "additional_tkns = ['number0','number1','number2']\n",
    "\n",
    "tokenizer.add_tokens(additional_tkns,special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "data_module = ArithmeticDataModule(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
    "\n",
    "        output = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "        \n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['text_input_ids']\n",
    "        attention_mask = batch['text_attention_mask']\n",
    "        labels = batch['labels']\n",
    "        labels_attention_mask = batch['labels_attention_mask']\n",
    "\n",
    "        loss, output = self(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['text_input_ids']\n",
    "        attention_mask = batch['text_attention_mask']\n",
    "        labels = batch['labels']\n",
    "        labels_attention_mask = batch['labels_attention_mask']\n",
    "\n",
    "        loss, output = self(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "        \n",
    "        # actual_op = labels\n",
    "        # pred_op = output\n",
    "        # acc = (labels == output).sum()/labels.shape[0]\n",
    "        # print(output)\n",
    "        # self.accuracy(output, labels)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        # self.log('val_acc', output, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['text_input_ids']\n",
    "        attention_mask = batch['text_attention_mask']\n",
    "        labels = batch['labels']\n",
    "        labels_attention_mask = batch['labels_attention_mask']\n",
    "\n",
    "        loss, output = self(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "            )\n",
    "        \n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArithmeticModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cf2d53cf33f17144\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cf2d53cf33f17144\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard  --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger('lightning_logs', name='Arithmetic-eqn')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    accelerator='gpu',\n",
    "    devices=[2],\n",
    "    enable_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs/Arithmetic-eqn\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/raid/home/ankitsingh1/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name     | Type                       | Params\n",
      "--------------------------------------------------------\n",
      "0 | model    | T5ForConditionalGeneration | 222 M \n",
      "1 | accuracy | Accuracy                   | 0     \n",
      "--------------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7338e1b15654b668cb0bb9849375d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/ankitsingh1/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/raid/home/ankitsingh1/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b778557fa17e491c8181e3afe3f6c741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d79174efc74df0a7f4aa4e2671d45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 117: 'val_loss' reached 2.77776 (best 2.77776), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6dcebd318e462db5c4c203fffd025e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 234: 'val_loss' reached 2.44440 (best 2.44440), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f10b3ae62a4a9fa1aaff476e157419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 351: 'val_loss' reached 1.86172 (best 1.86172), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdf7bb132cb45479dfed8acdff48081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 468: 'val_loss' reached 1.61169 (best 1.61169), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e4596d1a6345f0ad0356c3f4daa69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 585: 'val_loss' reached 1.30163 (best 1.30163), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fba71df3ec5467aa758febf1ad68ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 702: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdeec63fa274d569ad34cac8333b50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 819: 'val_loss' reached 1.18170 (best 1.18170), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec848b27b184b57adb01b8eaa2cde47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 936: 'val_loss' reached 1.09358 (best 1.09358), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8baf6d6c85b40f995208c8c32d00e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1053: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a13b20c872140f7afe14b52100c3ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1170: 'val_loss' reached 0.92988 (best 0.92988), saving model to '/raid/home/ankitsingh1/DLNLP/Assign5/checkpoints/best_checkpoint.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = ArithmeticModel.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path\n",
    ")\n",
    "\n",
    "trained_model.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eqn(text_question, text_description):\n",
    "    text_encoding = tokenizer(\n",
    "        text_question,\n",
    "        text_description,\n",
    "        max_length=396,\n",
    "        padding='max_length',\n",
    "        truncation=\"only_second\",\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=text_encoding['input_ids'],\n",
    "        attention_mask=text_encoding['attention_mask'],\n",
    "        max_length=10,\n",
    "        num_beams=1,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "    \n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_row = test_df.iloc[0]\n",
    "\n",
    "# eqn = sample_row['Equation']\n",
    "\n",
    "eqn_preds = compute_eqn('how many apples are in the basket ?', 'number0 red apples and number1 green apples are in the basket .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+ number0 number1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_num = {'number0':0, 'number1':1, 'number2':2,'number3':3,'number4':4,'number5':5,'number6':6,'number7':7,'number8':8,\n",
    "            'number9':9}\n",
    "def replace_with_numbers(eqn, nums):\n",
    "    nums = nums.split()\n",
    "    # new_eqn = eqn\n",
    "    for tok in eqn.split():\n",
    "        if tok in dict_num.keys():\n",
    "            # print(tok, nums[dict_num[tok]])\n",
    "            try:\n",
    "                eqn = eqn.replace(tok, nums[dict_num[tok]])\n",
    "            except:\n",
    "                print(dict_num, tok, nums)\n",
    "                continue\n",
    "    eqn = eqn.strip()\n",
    "    return eqn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+ 7 2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_with_numbers('+ number0 number1','7 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 program to evaluate a prefix expression.\n",
    "def isdigit(ch):\n",
    "    for i in ch:\n",
    "        if(ord(i) < 48 or ord(i) > 57) and i !='.':\n",
    "            return False\n",
    "    return True\n",
    "  \n",
    "def evaluatePrefix(expr):\n",
    "    try:\n",
    "        S = []\n",
    "        expr = expr.split()[::-1]\n",
    "        # print(expr)\n",
    "        for i in expr:\n",
    "            # print(i)\n",
    "            if isdigit(i):\n",
    "                S.append(float(i))\n",
    "            else:\n",
    "                a = S.pop()\n",
    "                b = S.pop()\n",
    "                if i == '+':\n",
    "                    S.append(a+b)\n",
    "                elif i == '-':\n",
    "                    S.append(a-b)\n",
    "                elif i == '*':\n",
    "                    S.append(a*b)\n",
    "                elif i == '/':\n",
    "                    S.append(a/b)\n",
    "            # print(S, i)\n",
    "        return S[-1]\n",
    "    \n",
    "    except :\n",
    "        return np.nan\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatePrefix('+ 7 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_on_test_data(x):\n",
    "    \n",
    "    pred_eqns = compute_eqn(x['Question'], x['Description'])\n",
    "    \n",
    "    final_eqn = replace_with_numbers(pred_eqns, x['Input Numbers'])\n",
    "    \n",
    "    ans = evaluatePrefix(final_eqn)\n",
    "    \n",
    "    if ans == int(ans):\n",
    "        return int(ans)\n",
    "    else:\n",
    "        return np.around(ans, decimals=2)\n",
    "    \n",
    "    # test_df['pred_eqns'] = test_df.apply(lambda x: compute_eqn(x['Question'], x['Description']), axis=1)\n",
    "    \n",
    "    # test_df['final_eqn'] = test_df.apply(lambda x: replace_with_numbers(x['pred_eqns'], x['Input Numbers']), axis=1)\n",
    "    \n",
    "    # test_df['output_final'] = test_df.final_eqn.apply(lambda x: evaluatePrefix(x))\n",
    "    \n",
    "    # return ans if ans - int(ans) else int(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, save=False):\n",
    "    test_df = test_df.apply(lambda x:compute_on_test_data(x), axis=1).to_numpy()\n",
    "    test_df = [[int(i)] if  i == int(i) else [np.around(i,decimals=2)] for i in test_df]\n",
    "    if save:\n",
    "        with open(\"abcd.csv\",\"a\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in test_df:\n",
    "                writer.writerow(row)\n",
    "    return test_df\n",
    "    # test_df['output_pred'].to_csv('abc.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38],\n",
       " [18],\n",
       " [66018],\n",
       " [-1],\n",
       " [45],\n",
       " [87],\n",
       " [320],\n",
       " [2],\n",
       " [-18],\n",
       " [-65],\n",
       " [9.56],\n",
       " [54],\n",
       " [0.57],\n",
       " [101],\n",
       " [120],\n",
       " [162],\n",
       " [-12.4],\n",
       " [25],\n",
       " [67],\n",
       " [76],\n",
       " [1029],\n",
       " [15],\n",
       " [22],\n",
       " [57],\n",
       " [8],\n",
       " [612],\n",
       " [176],\n",
       " [40],\n",
       " [44],\n",
       " [6],\n",
       " [660],\n",
       " [6],\n",
       " [1411],\n",
       " [16],\n",
       " [63],\n",
       " [27],\n",
       " [345],\n",
       " [29],\n",
       " [11],\n",
       " [94],\n",
       " [11],\n",
       " [203],\n",
       " [-5],\n",
       " [63],\n",
       " [2],\n",
       " [53],\n",
       " [42],\n",
       " [6],\n",
       " [1.5]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = test_df.copy()\n",
    "pred_y = predict(sample_df, save=True)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67225e902c436798ce86437353744102e33ba4d68fae561004183084f442db90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
